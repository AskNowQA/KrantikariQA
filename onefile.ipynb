{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_interface: Loading Word Vector to Memory.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import  DataLoader\n",
    "\n",
    "\n",
    "from utils import prepare_vocab_continous as vocab_master\n",
    "from utils import query_graph_to_sparql as sparql_constructor\n",
    "from utils import embeddings_interface\n",
    "import network_rdftype as net_rdftype\n",
    "import network_intent as net_intent\n",
    "import data_loader as dl\n",
    "import auxiliary as aux\n",
    "import network as net\n",
    "\n",
    "from pprint import pprint\n",
    "import ConfigParser\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "sparql_constructor.init(embeddings_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and setting up config parser\n",
    "config = ConfigParser.ConfigParser()\n",
    "config.readfp(open('configs/macros.cfg'))\n",
    "\n",
    "#setting up device,model name and loss types.\n",
    "training_model = 'bilstm_dot'\n",
    "_dataset = 'lcquad'\n",
    "pointwise = False\n",
    "_debug = False\n",
    "\n",
    "\n",
    "#Loading relations file.\n",
    "COMMON_DATA_DIR = 'data/data/common'\n",
    "INTENTS = ['count', 'ask', 'list']\n",
    "RDFTYPES = ['x', 'uri', 'none']\n",
    "\n",
    "_dataset_specific_data_dir = 'data/data/%(dataset)s/' % {'dataset': _dataset}\n",
    "_relations = aux.load_relation(COMMON_DATA_DIR)\n",
    "_word_to_id = aux.load_word_list(COMMON_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model specific paramters\n",
    "parameter_dict = {}\n",
    "parameter_dict['dataset'] = _dataset\n",
    "parameter_dict['max_length'] = int(config.get(training_model, 'max_length'))\n",
    "parameter_dict['hidden_size'] = int(config.get(training_model, 'hidden_size'))\n",
    "parameter_dict['number_of_layer'] = int(config.get(training_model, 'number_of_layer'))\n",
    "parameter_dict['embedding_dim'] = int(config.get(training_model, 'embedding_dim'))\n",
    "parameter_dict['vocab_size'] = int(config.get(training_model, 'vocab_size'))\n",
    "parameter_dict['batch_size'] = int(config.get(training_model, 'batch_size'))\n",
    "parameter_dict['bidirectional'] = bool(config.get(training_model, 'bidirectional'))\n",
    "parameter_dict['prune_corechain_candidates'] = bool(config.get('runtime', 'prune_corechain_candidates'))\n",
    "parameter_dict['_neg_paths_per_epoch_train'] = int(config.get(training_model, '_neg_paths_per_epoch_train'))\n",
    "parameter_dict['_neg_paths_per_epoch_validation'] = int(config.get(training_model, '_neg_paths_per_epoch_validation'))\n",
    "parameter_dict['total_negative_samples'] = int(config.get(training_model, 'total_negative_samples'))\n",
    "parameter_dict['epochs'] = int(config.get(training_model, 'epochs'))\n",
    "parameter_dict['dropout'] = float(config.get(training_model, 'dropout'))\n",
    "parameter_dict['dropout_rec'] = float(config.get(training_model, 'dropout_rec'))\n",
    "parameter_dict['dropout_in'] = float(config.get(training_model, 'dropout_in'))\n",
    "if training_model == 'cnn_dot':\n",
    "    parameter_dict['output_dim'] = int(config.get(training_model, 'output_dim'))\n",
    "\n",
    "# Update parameters\n",
    "parameter_dict['_dataset_specific_data_dir'] = _dataset_specific_data_dir\n",
    "parameter_dict['_model_dir'] = './data/models/'\n",
    "\n",
    "parameter_dict['corechainmodel'] = 'bilstm_dot'\n",
    "parameter_dict['corechainmodelnumber'] = '59'\n",
    "\n",
    "parameter_dict['intentmodel'] = 'bilstm_dense'\n",
    "parameter_dict['intentmodelnumber'] = '4'\n",
    "\n",
    "parameter_dict['rdftypemodel'] = 'bilstm_dense'\n",
    "parameter_dict['rdftypemodelnumber'] = '2'\n",
    "\n",
    "parameter_dict['rdfclassmodel'] = 'bilstm_dot'\n",
    "parameter_dict['rdfclassmodelnumber'] = '0'\n",
    "\n",
    "TEMP = aux.data_loading_parameters(_dataset,parameter_dict,runtime=True)\n",
    "\n",
    "_dataset_specific_data_dir,_model_specific_data_dir,_file,\\\n",
    "           _max_sequence_length,_neg_paths_per_epoch_train,\\\n",
    "            _neg_paths_per_epoch_validation,_training_split,_validation_split,_index= TEMP\n",
    "\n",
    "_data, _gloveid_to_embeddingid, _vectors = dl.create_dataset_runtime(file=_file,_dataset=_dataset,\n",
    "                                  _dataset_specific_data_dir=_dataset_specific_data_dir,\n",
    "                                  split_point=.80)\n",
    "\n",
    "parameter_dict['vectors'] = _vectors\n",
    "\n",
    "# For interpretability's sake\n",
    "gloveid_to_embeddingid , embeddingid_to_gloveid, word_to_gloveid, \\\n",
    "    gloveid_to_word = aux.load_embeddingid_gloveid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswering:\n",
    "    \"\"\"\n",
    "        Usage:\n",
    "\n",
    "            qa = QuestionAnswering(parameter_dict, False, _word_to_id, device, True)\n",
    "            q = np.random.randint(0, 1233, (542))\n",
    "            p = np.random.randint(0, 123, (10, 55))\n",
    "            print(qa._predict_corechain(q,p))\n",
    "            print(\"intent: \", qa._predict_intent(q))\n",
    "            print(\"rdftype: \", qa._predict_rdftype(q))\n",
    "            print(\"rdfclass: \", qa._predict_rdfclass(q, p))\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, parameters, pointwise, word_to_id, device, debug):\n",
    "\n",
    "        self.parameters = parameters\n",
    "        self.pointwise = pointwise\n",
    "        self.debug = debug\n",
    "        self.device = device\n",
    "        self._word_to_id = word_to_id\n",
    "\n",
    "        # Load models\n",
    "        self._load_corechain_model()\n",
    "        self._load_rdftype_model()\n",
    "        self._load_rdfclass_model()\n",
    "        self._load_intentmodel()\n",
    "\n",
    "    def _load_corechain_model(self):\n",
    "\n",
    "        # Initialize the model\n",
    "        if self.parameters['corechainmodel'] == 'bilstm_dot':\n",
    "            self.corechain_model = net.BiLstmDot(_parameter_dict=self.parameters, _word_to_id=self._word_to_id,\n",
    "                                                 _device=self.device, _pointwise=self.pointwise, _debug=self.debug)\n",
    "\n",
    "        # Make the model path\n",
    "        model_path = os.path.join(self.parameters['_model_dir'], 'core_chain')\n",
    "        model_path = os.path.join(model_path, self.parameters['corechainmodel'])\n",
    "        model_path = os.path.join(model_path, self.parameters['dataset'])\n",
    "        model_path = os.path.join(model_path, self.parameters['corechainmodelnumber'])\n",
    "        model_path = os.path.join(model_path, 'model.torch')\n",
    "\n",
    "        # Pull the data from disk\n",
    "        model_dump = torch.load(model_path)\n",
    "\n",
    "        # Load parameters\n",
    "        for key in self.corechain_model.prepare_save():\n",
    "            key[1].load_state_dict(model_dump[key[0]])\n",
    "\n",
    "    def _load_rdfclass_model(self):\n",
    "\n",
    "        # Initialize the model\n",
    "        if self.parameters['rdfclassmodel'] == 'bilstm_dot':\n",
    "            self.corechain_model = net.BiLstmDot(_parameter_dict=self.parameters, _word_to_id=self._word_to_id,\n",
    "                                                 _device=self.device, _pointwise=self.pointwise, _debug=self.debug)\n",
    "\n",
    "        # Make the model path\n",
    "        model_path = os.path.join(self.parameters['_model_dir'], 'rdf_class')\n",
    "        model_path = os.path.join(model_path, self.parameters['rdfclassmodel'])\n",
    "        model_path = os.path.join(model_path, self.parameters['dataset'])\n",
    "        model_path = os.path.join(model_path, self.parameters['rdfclassmodelnumber'])\n",
    "        model_path = os.path.join(model_path, 'model.torch')\n",
    "\n",
    "        # Pull the data from disk\n",
    "        model_dump = torch.load(model_path)\n",
    "\n",
    "        # Load parameters\n",
    "        for key in self.corechain_model.prepare_save():\n",
    "            key[1].load_state_dict(model_dump[key[0]])\n",
    "\n",
    "    def _load_rdftype_model(self):\n",
    "        # Initialize the model\n",
    "        self.rdftype_model = net_rdftype.RdfTypeClassifier(_parameter_dict=self.parameters,\n",
    "                                                           _word_to_id=self._word_to_id,\n",
    "                                                           _device=self.device)\n",
    "\n",
    "        # Make model path like:\n",
    "        # ('model with accuracy ', 0.998, 'stored at', 'data/models/intent/bilstm_dense/lcquad/2/model.torch')\n",
    "        model_path = os.path.join(self.parameters['_model_dir'], 'rdf_type')\n",
    "        model_path = os.path.join(model_path, self.parameters['rdftypemodel'])\n",
    "        model_path = os.path.join(model_path, self.parameters['dataset'])\n",
    "        model_path = os.path.join(model_path, self.parameters['rdftypemodelnumber'])\n",
    "        model_path = os.path.join(model_path, 'model.torch')\n",
    "\n",
    "        # Pull data from disk\n",
    "        model_dump = torch.load(model_path)\n",
    "\n",
    "        # Load parameters\n",
    "        for key in self.rdftype_model.prepare_save():\n",
    "            key[1].load_state_dict(model_dump[key[0]])\n",
    "\n",
    "    def _load_intentmodel(self):\n",
    "\n",
    "        # Initialize the model\n",
    "        self.intent_model = net_intent.IntentClassifier(_parameter_dict=self.parameters,\n",
    "                                                        _word_to_id=self._word_to_id,\n",
    "                                                        _device=self.device)\n",
    "\n",
    "        # Make model path like:\n",
    "        # ('model with accuracy ', 0.998, 'stored at', 'data/models/intent/bilstm_dense/lcquad/2/model.torch')\n",
    "        model_path = os.path.join(self.parameters['_model_dir'], 'intent')\n",
    "        model_path = os.path.join(model_path, self.parameters['intentmodel'])\n",
    "        model_path = os.path.join(model_path, self.parameters['dataset'])\n",
    "        model_path = os.path.join(model_path, self.parameters['intentmodelnumber'])\n",
    "        model_path = os.path.join(model_path, 'model.torch')\n",
    "\n",
    "        # Pull data from disk\n",
    "        model_dump = torch.load(model_path)\n",
    "\n",
    "        # Load parameters\n",
    "        for key in self.intent_model.prepare_save():\n",
    "            key[1].load_state_dict(model_dump[key[0]])\n",
    "\n",
    "    def _predict_corechain(self, _q, _p):\n",
    "        \"\"\"\n",
    "            Given a datapoint (question, paths) encoded in  embedding_vocab,\n",
    "                run the model's predict and find the best corechain.\n",
    "\n",
    "            _q: (<var len>)\n",
    "            _p: (100/500, <var len>)\n",
    "\n",
    "            returns score: (100/500)\n",
    "        \"\"\"\n",
    "\n",
    "        # Pad questions\n",
    "        Q = np.zeros((len(_p), self.parameters['max_length']))\n",
    "        Q[:, :min(len(_q), self.parameters['max_length'])] = \\\n",
    "            np.repeat(_q[np.newaxis, :min(len(_q), self.parameters['max_length'])], repeats=len(_p), axis=0)\n",
    "\n",
    "        # Pad paths\n",
    "        P = np.zeros((len(_p), self.parameters['max_length']))\n",
    "        for i in range(len(_p)):\n",
    "            P[i, :min(len(_p[i]), self.parameters['max_length'])] = \\\n",
    "                _p[i][:min(len(_p[i]), self.parameters['max_length'])]\n",
    "\n",
    "        # Convert np to torch stuff\n",
    "        Q = torch.tensor(Q, dtype=torch.long, device=self.device)\n",
    "        P = torch.tensor(P, dtype=torch.long, device=self.device)\n",
    "\n",
    "        if self.debug:\n",
    "            print(\"Q: \", Q.shape, \" P: \", P.shape)\n",
    "\n",
    "            # We then pass them through a predict function and get a score array.\n",
    "        score = self.corechain_model.predict(ques=Q, paths=P, device=self.device)\n",
    "\n",
    "        return score.detach().cpu().numpy()\n",
    "\n",
    "    def _predict_rdfclass(self, _q, _p):\n",
    "        \"\"\"\n",
    "            Given a datapoint (question, paths) encoded in  embedding_vocab,\n",
    "                run the model's predict and find the best corechain.\n",
    "\n",
    "            _q: (<var len>)\n",
    "            _p: (100/500, <var len>)\n",
    "\n",
    "            returns score: (100/500)\n",
    "        \"\"\"\n",
    "\n",
    "        # Pad questions\n",
    "        Q = np.zeros((len(_p), self.parameters['max_length']))\n",
    "        Q[:, :min(len(_q), self.parameters['max_length'])] = \\\n",
    "            np.repeat(_q[np.newaxis, :min(len(_q), self.parameters['max_length'])], repeats=len(_p), axis=0)\n",
    "\n",
    "        # Pad paths\n",
    "        P = np.zeros((len(_p), self.parameters['max_length']))\n",
    "        for i in range(len(_p)):\n",
    "            P[i, :min(len(_p[i]), self.parameters['max_length'])] = \\\n",
    "                _p[i][:min(len(_p[i]), self.parameters['max_length'])]\n",
    "\n",
    "        # Convert np to torch stuff\n",
    "        Q = torch.tensor(Q, dtype=torch.long, device=self.device)\n",
    "        P = torch.tensor(P, dtype=torch.long, device=self.device)\n",
    "\n",
    "        # We then pass them through a predict function and get a score array.\n",
    "        score = self.corechain_model.predict(ques=Q, paths=P, device=self.device)\n",
    "\n",
    "        return score.detach().cpu().numpy()\n",
    "\n",
    "    def _predict_intent(self, _q):\n",
    "        \"\"\"\n",
    "            Given a question, it runs a distribution over possible intents (ask/count/list)\n",
    "\n",
    "            _q: (<var len>)\n",
    "\n",
    "            returns: np.arr shape (3)\n",
    "        \"\"\"\n",
    "\n",
    "        # Pad the question\n",
    "        Q = np.zeros(self.parameters['max_length'])\n",
    "        Q[:min(_q.shape[0], self.parameters['max_length'])] = _q[:min(_q.shape[0], self.parameters['max_length'])]\n",
    "\n",
    "        data = {'ques_batch': Q.reshape(1, Q.shape[0])}\n",
    "\n",
    "        # Get prediction\n",
    "        score = self.intent_model.predict(data, self.device)\n",
    "\n",
    "        return score.detach().cpu().numpy()\n",
    "\n",
    "    def _predict_rdftype(self, _q):\n",
    "        \"\"\"\n",
    "            Given a question, it runs a distribution over possible places where we attach an rdftype constraint\n",
    "                (x/uri/none)\n",
    "\n",
    "            _q: (<var len>)\n",
    "\n",
    "            returns: np.arr shape (3)\n",
    "        \"\"\"\n",
    "\n",
    "        # Pad the question\n",
    "        Q = np.zeros(self.parameters['max_length'])\n",
    "        Q[:min(_q.shape[0], self.parameters['max_length'])] = _q[:min(_q.shape[0], self.parameters['max_length'])]\n",
    "\n",
    "        data = {'ques_batch': Q.reshape(1, Q.shape[0])}\n",
    "\n",
    "        # Get prediction\n",
    "        score = self.rdftype_model.predict(data, self.device)\n",
    "\n",
    "        return score.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_paths(data, relations, gloveid_to_embeddingid, qald=False):\n",
    "    \"\"\"\n",
    "    :param data: a data node of id_big_data\n",
    "    relations : a dictionary which maps relation id to meta inforamtion like surface form, embedding id\n",
    "    of surface form etc.\n",
    "    :return: unpadded , continous id spaced question, positive path, negative paths\n",
    "\n",
    "    @TODO: remove from here, and use dataloader version\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    question = np.asarray(data['uri']['question-id'])\n",
    "    # questions = pad_sequences([question], maxlen=max_length, padding='post')\n",
    "\n",
    "    # inverse id version of positive path and creating a numpy version\n",
    "    positive_path_id = data['parsed-data']['path_id']\n",
    "    no_positive_path = False\n",
    "    if positive_path_id == [-1]:\n",
    "        positive_path = np.asarray([-1])\n",
    "        no_positive_path = True\n",
    "    else:\n",
    "        positive_path = []\n",
    "        for path in positive_path_id:\n",
    "            positive_path += [embeddings_interface.SPECIAL_CHARACTERS.index(path[0])]\n",
    "            positive_path += relations[int(path[1:])][3].tolist()\n",
    "        positive_path = np.asarray(positive_path)\n",
    "    # padded_positive_path = pad_sequences([positive_path], maxlen=max_length, padding='post')\n",
    "\n",
    "    # negative paths from id to surface form id\n",
    "    negative_paths_id = data['uri']['hop-2-properties'] + data['uri']['hop-1-properties']\n",
    "    negative_paths = []\n",
    "    for neg_path in negative_paths_id:\n",
    "        negative_path = []\n",
    "        for path in neg_path:\n",
    "            try:\n",
    "                negative_path += [embeddings_interface.SPECIAL_CHARACTERS.index(path)]\n",
    "            except ValueError:\n",
    "                negative_path += relations[int(path)][3].tolist()\n",
    "        negative_paths.append(np.asarray(negative_path))\n",
    "    negative_paths = np.asarray(negative_paths)\n",
    "    # negative paths padding\n",
    "    # padded_negative_paths = pad_sequences(negative_paths, maxlen=max_length, padding='post')\n",
    "\n",
    "    # explicitly remove any positive path from negative path\n",
    "    negative_paths = dl.remove_positive_path(positive_path, negative_paths)\n",
    "\n",
    "    # remap all the id's to the continous id space.\n",
    "\n",
    "    # passing all the elements through vocab\n",
    "    question = np.asarray([gloveid_to_embeddingid[key] for key in question])\n",
    "    if not no_positive_path:\n",
    "        positive_path = np.asarray([gloveid_to_embeddingid[key] for key in positive_path])\n",
    "    for i in range(0, len(negative_paths)):\n",
    "        # temp = []\n",
    "        for j in xrange(0, len(negative_paths[i])):\n",
    "            try:\n",
    "                negative_paths[i][j] = gloveid_to_embeddingid[negative_paths[i][j]]\n",
    "            except:\n",
    "                negative_paths[i][j] = gloveid_to_embeddingid[0]\n",
    "                # negative_paths[i] = np.asarray(temp)\n",
    "                # negative_paths[i] = np.asarray([vocab[key] for key in negative_paths[i] if key in vocab.keys()])\n",
    "    if qald:\n",
    "        return question, positive_path, negative_paths, no_positive_path\n",
    "    return question, positive_path, negative_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_candidate_space(question, paths, k=None):\n",
    "    \"\"\"\n",
    "        Boilerplate to reduce the number of valid paths.\n",
    "        Note: path[0] is the correct path.\n",
    "            Should we remove it? Should we not?\n",
    "\n",
    "        As of now it returns an index\n",
    "    \"\"\"\n",
    "\n",
    "    return np.arange(len(paths))\n",
    "\n",
    "def create_sparql(log, data, embeddings_interface, embeddingid_to_gloveid, relations):\n",
    "    \"\"\"\n",
    "        Creates a query graph from logs and sends it to sparql_constructor\n",
    "            for getting a valid SPARQL query (or results) back.\n",
    "\n",
    "\n",
    "        Query graph is a dict containing:\n",
    "            best_path,\n",
    "            intent,\n",
    "            rdf_constraint,\n",
    "            rdf_constraint_type,\n",
    "            rdf_best_path\n",
    "\n",
    "    :param log: dict made using answer_question function\n",
    "    :param embeddings_interface: the file\n",
    "    :param embeddingid_to_gloveid: reverse vocab dict\n",
    "    :param relations: the relations dict\n",
    "    :return: sparql query as string\n",
    "    \"\"\"\n",
    "    query_graph = {}\n",
    "    query_graph['intent'] = log['pred_intent']\n",
    "    query_graph['best_path'] = log['pred_path']\n",
    "    query_graph['rdf_constraint_type'] = log['pred_rdf_type']\n",
    "    query_graph['rdf_best_path'] = log['pred_rdf_class']\n",
    "    query_graph['entities'] = data['parsed-data']['entity']\n",
    "    query_graph['rdf_constraint'] = False if log['pred_rdf_type'] == 'none' else True\n",
    "\n",
    "    return sparql_constructor.convert(_graph=query_graph, relations=relations,\n",
    "                                        embeddings_interface=embeddings_interface,\n",
    "                                        embeddingid_to_gloveid=embeddingid_to_gloveid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corechain_prediction(question, paths, positive_path, negative_paths, no_positive_path):\n",
    "    '''\n",
    "        Why is path needed ?\n",
    "    '''\n",
    "\n",
    "    # Remove if adding to class\n",
    "    global qa\n",
    "\n",
    "    mrr = 0\n",
    "    best_path = ''\n",
    "    path_predicted_correct = False\n",
    "\n",
    "    if no_positive_path and len(negative_paths) == 0:\n",
    "        '''\n",
    "            There exists no positive path and also no negative paths\n",
    "                Why does this quest exists ? \n",
    "                    > Probably in qald\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    if not no_positive_path and len(negative_paths) == 0:\n",
    "        '''\n",
    "            There exists a positive path and there exists no negative path\n",
    "        '''\n",
    "        best_path = positive_path\n",
    "        mrr = 1\n",
    "        path_predicted_correct = True\n",
    "\n",
    "    if (not no_positive_path or no_positive_path) and len(negative_paths) != 0:\n",
    "        '''\n",
    "            There exists positive path and also negative paths\n",
    "            path = positive_path + negative_paths    \n",
    "        '''\n",
    "        output = qa._predict_corechain(question, paths)\n",
    "        best_path_index = np.argmax(output)\n",
    "        best_path = paths[best_path_index]\n",
    "\n",
    "        # Calculate mrr here\n",
    "        mrr = 0\n",
    "        if best_path_index == 0:\n",
    "            path_predicted_correct = True\n",
    "\n",
    "        mrr_output = np.argsort(output)[::-1]\n",
    "        mrr_output = mrr_output.tolist()\n",
    "        mrr = mrr_output.index(0) + 1.0\n",
    "\n",
    "        if mrr != 0:\n",
    "            mrr = 1.0 / mrr\n",
    "\n",
    "    return mrr, best_path, path_predicted_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(qa, index, data, gloveid_to_embeddingid, embeddingid_to_gloveid, relations, parameter_dict):\n",
    "    \"\"\"\n",
    "        Uses everything to do everyhing for one data instance (one question, subgraph etc).\n",
    "    \"\"\"\n",
    "\n",
    "    log = {}\n",
    "    log['question'] = None\n",
    "    log['true_path'] = None\n",
    "    log['true_intent'] = None\n",
    "    log['true_rdf_type'] = None\n",
    "    log['true_rdf_class'] = None\n",
    "    log['pred_path'] = None\n",
    "    log['pred_intent'] = None\n",
    "    log['pred_rdf_type'] = None\n",
    "    log['pred_rdf_class'] = None\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    question, positive_path, negative_paths, no_positive_path = dl.construct_paths(data, qald=True,\n",
    "                                                                                   relations=relations,\n",
    "                                                                                   gloveid_to_embeddingid=gloveid_to_embeddingid)\n",
    "    log['question'] = question\n",
    "\n",
    "    '''\n",
    "        @some hack\n",
    "        if the dataset is LC-QUAD and data['pop'] \n",
    "            is false then the positive path has been forcefully inserted and needs to be removed.\n",
    "    '''\n",
    "    if parameter_dict['dataset'] == 'lcquad':\n",
    "        try:\n",
    "            if data['pop'] == False:\n",
    "                no_positive_path = True\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    # ##############################################\n",
    "    \"\"\"\n",
    "        Core chain prediction\n",
    "    \"\"\"\n",
    "    # ##############################################\n",
    "    if no_positive_path:\n",
    "        '''\n",
    "            There is no positive path, maybe we do something intelligent\n",
    "        '''\n",
    "        log['true_path'] = [-1]\n",
    "        nps = [n.tolist() for n in negative_paths]\n",
    "        paths = nps\n",
    "        index_selected_paths = prune_candidate_space(question, paths, parameter_dict['prune_corechain_candidates'])\n",
    "\n",
    "    else:\n",
    "\n",
    "        pp = [positive_path.tolist()]\n",
    "        nps = [n.tolist() for n in negative_paths]\n",
    "        paths = pp + nps\n",
    "        if parameter_dict['prune_corechain_candidates']:\n",
    "            index_selected_paths = prune_candidate_space(question, paths, parameter_dict['prune_corechain_candidates'])\n",
    "\n",
    "            if index_selected_paths[-1] == 0:\n",
    "                #  Counts the number of times just using  word2vec similarity, the best path came the most similar.\n",
    "                # This will only work if CANDIDATE_SPACE is not none.\n",
    "                metrics['word_vector_accuracy_counter'] = 1\n",
    "        else:\n",
    "            index_selected_paths = prune_candidate_space(question, paths, len(paths))\n",
    "\n",
    "        log['true_path'] = pp[0]\n",
    "\n",
    "    # Put the pruning index over the paths\n",
    "    paths = [paths[i] for i in index_selected_paths]\n",
    "\n",
    "    '''\n",
    "        Converting paths to numpy array\n",
    "    '''\n",
    "    for i in range(len(paths)):\n",
    "        paths[i] = np.asarray(paths[i])\n",
    "    paths = np.asarray(paths)\n",
    "\n",
    "    cc_mrr, best_path, cc_acc = corechain_prediction(question,\n",
    "                                                     paths, positive_path,\n",
    "                                                     negative_paths, no_positive_path)\n",
    "    log['pred_path'] = best_path\n",
    "    metrics['core_chain_accuracy_counter'] = cc_acc\n",
    "    metrics['core_chain_mrr_counter'] = cc_mrr\n",
    "    metrics['num_paths'] = len(paths)\n",
    "\n",
    "    # ##############################################\n",
    "    \"\"\"\n",
    "        Intent, rdftype prediction\n",
    "\n",
    "        Straightforward.\n",
    "\n",
    "        Metrics: accuracy\n",
    "    \"\"\"\n",
    "    # ##############################################\n",
    "    # Get intent\n",
    "    intent_pred = np.argmax(qa._predict_intent(question))\n",
    "    intent_true = np.argmax(net_intent.get_y(data))\n",
    "    intent_acc = 1 if intent_pred == intent_true else 0\n",
    "    metrics['intent_accuracy_counter'] = intent_acc\n",
    "    intent = INTENTS[intent_pred]\n",
    "\n",
    "    log['true_intent'] = INTENTS[intent_true]\n",
    "    log['pred_intent'] = INTENTS[intent_pred]\n",
    "\n",
    "    # Get rdftype\n",
    "    rdftype_pred = np.argmax(qa._predict_rdftype(question))\n",
    "    rdftype_true = np.argmax(net_rdftype.get_y(data))\n",
    "    rdftype_acc = 1 if rdftype_pred == rdftype_true else 0\n",
    "    metrics['rdftype_accuracy_counter'] = rdftype_acc\n",
    "    rdftype = RDFTYPES[rdftype_pred]\n",
    "\n",
    "    log['true_rdf_type'] = RDFTYPES[rdftype_true]\n",
    "    log['pred_rdf_type'] = RDFTYPES[rdftype_pred]\n",
    "\n",
    "    # ##############################################\n",
    "    \"\"\"\n",
    "        RDF class prediction.\n",
    "\n",
    "            do this only if we need to, based on the prediction of rdftype model.\n",
    "    \"\"\"\n",
    "    # ##############################################\n",
    "\n",
    "    # Add dummy rdfclass logs and metrics\n",
    "    log['true_rdf_class'] = None\n",
    "    log['pred_rdf_class'] = None\n",
    "    metrics['rdfclass_accuracy_counter'] = None\n",
    "\n",
    "    if rdftype == \"none\":\n",
    "\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        \"\"\"\n",
    "            We do need an rdf constraint.\n",
    "            We let the rdf class model (ranker) choose between both x and uri paths, \n",
    "                and the rdf type model is just used to see if we need paths at all.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        rdf_candidates = sparql_constructor.rdf_type_candidates(data, best_path, gloveid_to_embeddingid, relations, embeddingid_to_gloveid)\n",
    "\n",
    "        if rdf_candidates:\n",
    "\n",
    "            rdf_candidate_pred = qa._predict_rdfclass(_q=question, _p=rdf_candidates)\n",
    "\n",
    "            best_rdf_path = rdf_candidates[np.argmax(rdf_candidate_pred)]\n",
    "\n",
    "                   \n",
    "\n",
    "        else:\n",
    "\n",
    "            # No candidates found\n",
    "            best_rdf_path = []\n",
    "            \n",
    "        # @TODO: as of now we don't have ground truth so we add a 0 in metrics and 0 in log      \n",
    "        log['true_rdf_class'] = 0\n",
    "        log['pred_rdf_class'] = best_rdf_path\n",
    "        metrics['rdfclass_accuracy_counter'] = 0\n",
    "            \n",
    "    return log, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartiallyPretrainedWordEmb: vectors loaded in 0.018 second\n",
      "PartiallyPretrainedWordEmb: words loaded in 0.048 second\n",
      "PartiallyPretrainedWordEmb: dictionary created in 0.029 second\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FlatEncoder:\n\tWhile copying the parameter named \"emb.mixmask\", whose dimensions in the model are torch.Size([18589]) and whose dimensions in the checkpoint are torch.Size([13242]).\n\tWhile copying the parameter named \"emb.embedding.weight\", whose dimensions in the model are torch.Size([18589, 300]) and whose dimensions in the checkpoint are torch.Size([13242, 300]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ededf946b47f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mLogging\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'runtime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mqa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuestionAnswering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpointwise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_word_to_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_debug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-4f4cb3dfbba7>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parameters, pointwise, word_to_id, device, debug)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Load models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_corechain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_rdftype_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_rdfclass_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4f4cb3dfbba7>\u001b[0m in \u001b[0;36m_load_corechain_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Load parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorechain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dump\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_rdfclass_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/priyansh/virtualenvironment/pwc-reg-m/local/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 721\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FlatEncoder:\n\tWhile copying the parameter named \"emb.mixmask\", whose dimensions in the model are torch.Size([18589]) and whose dimensions in the checkpoint are torch.Size([13242]).\n\tWhile copying the parameter named \"emb.embedding.weight\", whose dimensions in the model are torch.Size([18589, 300]) and whose dimensions in the checkpoint are torch.Size([13242, 300])."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Different counters and metrics to store accuracy of diff modules\n",
    "\n",
    "        Core chain accuracy counter counts the number of time the core chain predicated is same as \n",
    "        positive path. This also includes for ask query.\n",
    "        The counter might confuse the property and the ontology. \n",
    "\n",
    "        Similar functionality with rdf_type and intent\n",
    "\n",
    "        **word vector accuracy counter**: \n",
    "            Counts the number of times just using  word2vec similarity, \n",
    "            the best path came the most similar. \n",
    "            This will only work if CANDIDATE_SPACE is not none.\n",
    "\n",
    "\"\"\"\n",
    "core_chain_accuracy_counter = 0\n",
    "core_chain_mrr_counter = 0\n",
    "intent_accuracy_counter = 0\n",
    "rdftype_accuracy_counter = 0\n",
    "query_graph_accuracy_counter = 0\n",
    "word_vector_accuracy_counter = 0  # @TODO: note this down on every occassion!\n",
    "core_chain_acc_log = []\n",
    "core_chain_mrr_log = []\n",
    "\n",
    "'''\n",
    "    c_flag  is true if the core_chain was correctly predicted. \n",
    "    same is the case for i_flag and r_flag, rt_flag (correct candidate for rdf type)\n",
    "'''\n",
    "c_flag, i_flag, r_flag, rt_flag = False, False, False, False\n",
    "\n",
    "'''\n",
    "    Stores tuple of (fmeasure,precision,recall)\n",
    "'''\n",
    "results = []\n",
    "\n",
    "Logging = parameter_dict.copy()\n",
    "Logging['runtime'] = []\n",
    "\n",
    "qa = QuestionAnswering(parameter_dict, pointwise, _word_to_id, device, _debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "startindex = 813\n",
    "for index, data in enumerate(_data[startindex:]):\n",
    "\n",
    "    index += startindex\n",
    "    \n",
    "    log, metrics = answer_question(qa=qa,\n",
    "                                   index=index,\n",
    "                                   data=data,\n",
    "                                   gloveid_to_embeddingid=_gloveid_to_embeddingid,\n",
    "                                   embeddingid_to_gloveid=embeddingid_to_gloveid,\n",
    "                                   relations=_relations,\n",
    "                                   parameter_dict=parameter_dict)\n",
    "    \n",
    "#     log, metrics = answer_question(qa=None,\n",
    "#                                    index=None,\n",
    "#                                    data=None,\n",
    "#                                    gloveid_to_embeddingid=None,\n",
    "#                                    embeddingid_to_gloveid=None,\n",
    "#                                    relations=None,\n",
    "#                                    parameter_dict=None)\n",
    "\n",
    "    sparql = create_sparql(log=log,\n",
    "                           data=data,\n",
    "                           embeddings_interface=embeddings_interface,\n",
    "                           embeddingid_to_gloveid=embeddingid_to_gloveid,\n",
    "                           relations=_relations)\n",
    "\n",
    "    # metrics = eval(data, log, metrics)\n",
    "\n",
    "    # Update logs\n",
    "    Logging['runtime'].append({'log': log, 'metrics': metrics})\n",
    "\n",
    "    # Update metrics\n",
    "    intent_accuracy_counter += metrics['intent_accuracy_counter']\n",
    "    rdftype_accuracy_counter += metrics['rdftype_accuracy_counter']\n",
    "    core_chain_accuracy_counter += metrics['core_chain_accuracy_counter']\n",
    "    core_chain_mrr_counter += metrics['core_chain_mrr_counter']\n",
    "    core_chain_acc_log.append(metrics['core_chain_accuracy_counter'])\n",
    "    core_chain_mrr_log.append(metrics['core_chain_mrr_counter'])\n",
    "\n",
    "    # Make shit interpretable\n",
    "    question = aux.id_to_word(log['question'], gloveid_to_word, embeddingid_to_gloveid, remove_pad=True)\n",
    "    true_path = aux.id_to_word(log['true_path'], gloveid_to_word, embeddingid_to_gloveid, remove_pad=True)\n",
    "    pred_path = aux.id_to_word(log['pred_path'], gloveid_to_word, embeddingid_to_gloveid, remove_pad=True)\n",
    "\n",
    "    print(\"#%s\" % index, \"\\n\\t\\bQues: \", question)\n",
    "    print(\"\\t\\bTPath: \", true_path, \"\\n\\t\\bPPath: \", pred_path)\n",
    "    print(\"\\t\\bTIntent: \", log['true_intent'])\n",
    "    print(\"\\t\\bPIntent: \", log['pred_intent'])\n",
    "    print(\"\\t\\bPRdftype: \", log['true_rdf_type'])\n",
    "    print(\"\\t\\bTRdftype: \", log['pred_rdf_type'])\n",
    "    print(\"\\t\\bPRdfclass: \", log['true_rdf_class'])\n",
    "    print(\"\\t\\bTRdfclass: \", log['pred_rdf_class'])\n",
    "\n",
    "    print(\"\")\n",
    "    pprint(log)\n",
    "    print(\"\")\n",
    "    pprint(metrics)\n",
    "    print(\"\\n\",sparql)\n",
    "    print(\"\\n################################\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
